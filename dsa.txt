Data Structures and algorithms

All Data Structures:
https://en.wikipedia.org/wiki/List_of_data_structures#Linear_data_structures
https://en.wikipedia.org/wiki/Data_structure

What is a "Data Structure":
a data structure is a data organization, management, and storage format that is usually chosen for efficient access to data. 
More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data

    ""
    Data structures provide a means to manage large amounts of data efficiently for uses such as large databases and internet indexing services. Usually, efficient data
    structures are key to designing efficient algorithms
    ""

Abstract Data Types:
https://en.wikipedia.org/wiki/Abstract_data_type
"
An abstract datatype is like a machine that has a control panel. The user(programmer) can put an item in, take items out, ask questions about the number of items, things like that. But the 
user(programmer) has no idea, and shouldn't know, how the machine is keeping track of the items.

For a real example there is a list type in c#. It doesn't matter if it is stores items as a linked list, an array, or whatever. All you(the programmer) care about is that it is a list.

An ADT is just like an interface but non-language specific. So no matter what language you're working in if you are writing a List datatype it should have the same handles/methods and they 
should work the same. But the inner workings of HOW they do this can be different.
"

Is a linked list an ADT? 
"
A linked list may well be considered an abstract data type since it's value is not atomic - per definition, a node in a linked list must contain both a value and a link to the next node.
If this is "homework" for a Java class as I understand most CS undergrads have to slog through in the US, ignore what I just said: then then principle is "yes sir, lists are not an ADT sir! :D
 I will not implement my own linked lists, sir! :D"
you are presumably trained to consider anything in the language that is part of the base library as axiomatic and therefore not an ADT. Just go with this, you want good grades.
"
so the answer varies, but seems like the consensus is that a *LL IS an ADT*

"linked list is an ADT, and every ADT is also a data structure, so linked list is both."
"A linked list is an abstract data type in the sense that it is a higher level container than just putting things in memory, 
and keeping a pointer variable for each item, and dealing with data that way.

On "Abstract Data Types" vs "Data Types":
"Assume a box and you put a label on that according to what you want to store in it, that label is called data type and how you arrange those boxes is data structures."
(below description says data sturctures are data types which doesn't seem to be the case, but ignore that part)
"Data structures also called data types are the particular ways of organizing data in a computer so that it can be used efficiently. Abstract data types (ADT) are set of values (the carrier set), and operations on these values
so ADTs can be seen as "a black box (abstraction) that provides some functions to manage a collection of data (data types)"

On ADT vs Data structure:
ADT is a logical description and data structure is concrete. ADT is the logical picture of the data and the operations to manipulate the component elements of the data. Data structure is the 
actual representation of the data during the implementation and the algorithms to manipulate the data elements. ADT is in the logical level and data structure is in the implementation level.

On "Abstraction" in CS:
""
In CS it means that you are taking something detailed and low-level and symbolizing it with an easier to use or simpler to deal with construct.
You are “abstracting” the interface up from the tiny changes and minuscule steps it takes to do a task into a tool that you can just use.
The ultimate abstract is said to be the “One Big Red Button” idea, where all you let the user do is push the button and the computer does it all. 
Abstraction in practical terms in not that, but the basic concept is like that.
""

on Data Type vs ADT vs Data Stucture:
""
A data type is a collection of values (its domain) together with a set of permissible operations on those values. An abstract data type (ADT) is a data type whose properties 
(domain and operations) are specified independently of any implementation. A data structure is the implementation of an ADT
""
(adt is a data type)
(data structure is an implementation of a ADT which is a data type)

this still seems obscure to me.


On "Representation Invariant" ("Rep Invariant"):

    "A condition that must be true over all valid concrete representations of a class. The representation invariant also defines the domain of the abstraction function."
    In many language a rep invariant "describes whether an instance of a type is well formed"

    for example: a rep invariant of a max-heap is that the parent of a node is always larger then that node (and vice versa for min-heaps) and likewise (another rep invariant) is that the root of a max-heap must be the largest item and the root of a min-heap must be the smallest
    - so we want to maintain this rep-invariant (max-heap or min-heap property) as we modify the heap
    - this is also called the "heap invariant" as I have now realized

    From MIT: (https://web.mit.edu/6.005/www/fa15/classes/13-abstraction-functions-rep-invariants/):

        from MIT on "invariants":
        "Resuming our discussion of what makes a good abstract data type, the final, and perhaps most important, property of a good abstract data type is that it preserves its own invariants"
        An invariant is a property of a program that is always true
            "Immutability is one crucial invariant that we’ve already encountered: once created, an immutable object should always represent the same value, for its entire lifetime"
        Saying that the ADT preserves its own invariants means that the ADT is responsible for ensuring that its own invariants hold. It doesn’t depend on good behavior from its clients

        " interesting
        When an ADT preserves its own invariants, reasoning about the code becomes much easier. If you can count on the fact that Strings never change, you can rule out that possibility when 
        you’re debugging code that uses Strings – or when you’re trying to establish an invariant for another ADT that uses Strings. Contrast that with a string type that guarantees that it 
        will be immutable only if its clients promise not to change it. Then you’d have to check all the places in the code where the string might be used.
        "

        from MIT on "rep exposure":
        - more details here just read linked article from MIT
        interesting section if you search "The problem is that Tweet leaked out a reference to a mutable object that its immutability depended on" and read the entire example on "immutability" - "We exposed the rep, in such a way that Tweet can no longer guarantee that its objects are immutable. Perfectly reasonable client code created a subtle bug."
            "In general, you should carefully inspect the argument types and return types of all your ADT operations. If any of the types are mutable, make sure your implementation doesn’t return direct references to its representation. Doing that creates rep exposure"

things to remember:
- subsets > subsequence > subarray
    - subsets take any in any order, subsequence take any as long as in order, subarray takes contiguous in order 
- read the question thoroughly, read examples, and ask questions
- realize and describe your assumptions
- #permutations > #combinations
- order doesn't matter in combos and does matter in perms so multiple permuations would map to the same combination
    - how to remember: A "combination lock" should really be called a "permutation lock".
- space complexity of say a counter of characters/numbers is actually O(1) because characters can only be a finite number of things
- number of substrings in a string is n^2 / number of subarrays in a list/array is n^2
    - n possible starting indices and n possible ending indices = O(n^2)
- number of subsequences in a string / subarrays in an array is 2^n (you can delete items, so you chose to take or not take each item for all n items = 2^n)
- the time complexity of finding all subsequences of size k in a string is O(n^k). For example, finding all subsequences of size 3 is O(n^3), which is much more efficient than the O(2^n) counterpart for finding *all* subsequences.
- the number of pairs that can be made if I have n items (and each pair is counted once and no item is paired with itself) is (n(n-1))/2
    - derivation: each item can be paired with n-1 different items. So that is n(n-1) pairs. But pairs would all be counted twice, hence the /2

bitwise:
- when OR'ing all items in an array, the OR bits tend towards 1 and can never return to 0 after (1 OR 0 is still 1, so once a bit is 1, it cannot return to 0)
- when AND'ing all items in an array, the AND bits tend towards 0 and can never return to 1 after (1 AND 0 is 0, so once a bit is 0, it cannot return to 1)
- similar rules do not apply for compounding XORs

general learning priiples for getting better at DSA/LC:
- try to avoid the "let me just change this and re-run the tests" mentality. When you change something you should train yourself to think about
    what different outcome it could produce and why

handle edge cases:
examples:

    for Hand of Straights - never considered that there could be duplicate numbers in the input list (even though it's in the exmaple) and setup a completely invalid solution
    https://leetcode.com/problems/hand-of-straights/description/


Solving Problems with the help of problem constraints
see https://leetcode.com/discuss/interview-question/1105473/solving-problems-with-aid-of-problem-constraints
how to determine for what input size each time complexity is suitable

other Notes
cam across SortedList from Python sortedcontainers collection, that basically provides a list data structure that maintains order and allows the following operations:
- add O(logn)
- find O(logn)
    [removing items]
    - discard value O(logn) (if value not a member, do nothing)
    - remove value O(logn) (item must be a member)
    - pop index O(logn)
- but not seeing a constant time poplargest or popsmallest
see https://grantjenks.com/docs/sortedcontainers/sortedlist.html#sortedcontainers.SortedList.pop

why not use this data structure instead of a heap in general? becuase heap optimizations like pushpop?
- its probably a little overkill for operations you can do with a heap
- make heap is O(n), make SortedList is O(nlogn)

also apparently the best way to sort a linked list is merge sort
see https://stackoverflow.com/questions/70049647/why-is-it-not-recommended-to-use-a-heap-to-sort-a-linkedlist

Evaluating time complexity: does modifying the input count towards space complexity? yes:

    Depending on the context, it's common to treat the input as read-only when analyzing auxiliary space.
    A separate notion is that of an in-place algorithm. In an in-place algorithm, we treat the input as writeable, and count the amount of extra space beyond that.
    If the context is not clear, I suggest that you specify explicitly whether you treat the input as writeable or not.
    but often it is assumed that if you modify the input, the Space Complexity is O(n), however, the extra space you speak of aka: "Auxiliary Space" is O(1).

    Space Complexity of an algorithm is the total space used by an algorithm at run time with respect to the input size.
    Always remember: "If you use it, count it." – If your algorithm uses the space, you have to count it in your Space Complexity analysis.

Size of Input -> Worst accepted algorithm
<=[10....11] -> O(N!) ,O(n^6)
<=[15......18] -> O(2^N*N^2)
<=[18......22] -> O(2^N*N)
<=100 -> O(N^4)
<=400 -> O(N^3)
<=2K -> O(N^2*logN)
<=10K -> O(N^2)
<=1M -> O(N*logN)
<=100M -> O(N),O(logN)

"
when I see constraints in problem like N>10^4 immeditaly it rings me the bell that i need something at least O(n*logn) or O(n) even better.
If i see n<1000 i am extra sure that my nested for loop solution is in right track.
"

XOR Notes
(A XOR B) XOR B = A
(A XOR B) XOR A = B

xoring values can increase the value to larger than both values

    2 XOR 1 = 3
    in binary:
    010 XOR 001 -=> 011

anything XOR itself is zero

    3 XOR 3 = 0
    binary:
    011 XOR 011 = 0

zero XOR anything is that anything

    0 XOR 48 = 48


anything xor anything else can never equal either of the two operators

    the following two are impossible:
    a XOR a = a
    a XOR b = b


XOR 4

0 XOR 4 = 4
1 XOR 4 = 4 + 1 = 5 (because completely different bits)
2 XOR 4 = 4 + 2 = 6 (because completely different bits)
3 XOR 4 = 4 + 3 = 7 (because completely different bits)\
4 XOR 4 = 0
5 XOR 4 = 1
6 XOR 4 = 2
7 XOR 4 = 3
8 XOR 4 = 12
